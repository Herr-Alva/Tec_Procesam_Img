{"cells":[{"cell_type":"markdown","metadata":{"id":"5fe98c97","cell_id":"3d495a0f52244a5bba65dbe7dcb0f70d","deepnote_cell_type":"markdown"},"source":"# Comprensión espacial 2D con Gemini 2.0\n\nCuaderno traducido al español por Matias Barreto para enseñar comprensión espacial 2D con Gemini 2.0.","block_group":"222ceb0589bc4fc39636090558c967d5"},{"cell_type":"markdown","metadata":{"id":"82017914","cell_id":"9693845642804b57ba22ceb3314fb012","deepnote_cell_type":"markdown"},"source":"## 1. Instalar el SDK\n\nInstalá el paquete `google-genai` usando pip para acceder a la API de Gemini.","block_group":"08b7aba61eb6428db5a63080d37718c7"},{"cell_type":"code","metadata":{"id":"82e2f094","cell_id":"9feec1e27fe0489286e48e8746fbafc3","deepnote_cell_type":"code"},"source":"%pip install -U -q google-genai","block_group":"83f38dced5bb4fa3b82166f61c919f1c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"7ae2c85a","cell_id":"63c72ca89c06459ab5d4b0412832afa7","deepnote_cell_type":"markdown"},"source":"## 2. Configurar la clave de API\n\nConfigurá tu clave de API de Google almacenada en un secreto de Colab o como variable de entorno. Si no tenés una clave, consultá la documentación oficial para obtenerla.","block_group":"02c235295c61487abef4831744e9042b"},{"cell_type":"code","metadata":{"id":"dcde839b","cell_id":"eaed56f1a9484e4db4c2d4fb26eae56f","deepnote_cell_type":"code"},"source":"from google.colab import userdata\nimport os\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')","block_group":"9fcd44c55231430c9d6a36fa7465c178","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"81e7bd1b","cell_id":"d2c5ec3653da4c5e9ae6db09e6cecde2","deepnote_cell_type":"markdown"},"source":"## 3. Inicializar el cliente del SDK\n\nInicializá el cliente de Gemini con tu clave de API para poder hacer solicitudes al modelo.","block_group":"aa869be4d42b40879454ce854f9ef43b"},{"cell_type":"code","metadata":{"id":"7a28fe0d","cell_id":"2b5fe9d683f54beb83d6f460dec15fc8","deepnote_cell_type":"code"},"source":"from google import genai\nfrom google.genai import types\n\ncliente = genai.Client(api_key=GOOGLE_API_KEY)","block_group":"b2806ca5ee0246cab6918dd1c42c9317","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"d7403f5f","cell_id":"8604528a59314741a9489879c3a53ab4","deepnote_cell_type":"markdown"},"source":"## 4. Seleccionar y configurar el modelo\n\nElegí el modelo de Gemini que quieras usar y configurá el nombre según tus necesidades. Los modelos 2.5 suelen dar mejores resultados para segmentación y razonamiento avanzado.","block_group":"7f87e8f45a3a4d19b7ff3ecb1814f543"},{"cell_type":"code","metadata":{"id":"4c88b6a9","cell_id":"8037c16b880e461091c52f824893d6c1","deepnote_cell_type":"code"},"source":"nombre_modelo = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true}","block_group":"7fa15eddfa56493fbf4399113249e27e","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"765e86da","cell_id":"6bc2a27c8d5b4bd6ae7690688b56612e","deepnote_cell_type":"markdown"},"source":"## 5. Definir instrucciones del sistema y configuración de seguridad\n\nDefiní las instrucciones del sistema para el modelo y configurá los parámetros de seguridad para el contenido generado.","block_group":"62c407f534a5400e951675cda828ec94"},{"cell_type":"code","metadata":{"id":"71c55504","cell_id":"6acfe8aae2ac4d25b623a40805df40a0","deepnote_cell_type":"code"},"source":"instrucciones_sistema_bbox = \"\"\"\n    Devolvé los bounding boxes como un array JSON con etiquetas. Nunca devuelvas máscaras ni código. Limitá a 25 objetos.\n    Si un objeto aparece varias veces, nombralos según alguna característica única (color, tamaño, posición, etc.).\n\"\"\"\nconfig_seguridad = [\n    types.SafetySetting(\n        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        threshold=\"BLOCK_ONLY_HIGH\",\n    ),\n]","block_group":"89abceb84c1d4fd3acef06af1114ff11","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"31b5a92b","cell_id":"f790e57ff8044b6c946737a5623db5cd","deepnote_cell_type":"markdown"},"source":"## 6. Importar módulos necesarios\n\nImportá todas las librerías y módulos requeridos, como PIL, requests, io, json, numpy, etc.","block_group":"5de2017fbd654593b9d47c8f5030fbb3"},{"cell_type":"code","metadata":{"id":"e723b240","cell_id":"ef2e0bdc11c145d68d1f215dd17e9a29","deepnote_cell_type":"code"},"source":"import google.generativeai as genai\nfrom PIL import Image\n\nimport io\nimport os\nimport requests\nfrom io import BytesIO\nimport json\nimport random\nimport numpy as np\nimport base64\nimport dataclasses\nfrom PIL import ImageDraw, ImageFont, ImageColor","block_group":"a670e00602ad496bb7471f9b4de5f88e","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"bfb1e0f2","cell_id":"7a2ec51c55e24611a0ebacd0716d61a5","deepnote_cell_type":"markdown"},"source":"## 7. Funciones utilitarias para procesamiento y visualización\n\nDefiní funciones para parsear la salida JSON, dibujar bounding boxes y segmentaciones sobre las imágenes.","block_group":"ce452af875da43098d0877e227dab4ab"},{"cell_type":"code","metadata":{"id":"60fdbcbb","cell_id":"99c7fcf6618a41218dbb7189002b8c33","deepnote_cell_type":"code"},"source":"# Parsear la salida JSON del modelo\ndef parsear_json(salida_json: str):\n    lineas = salida_json.splitlines()\n    for i, linea in enumerate(lineas):\n        if linea == \"```json\":\n            salida_json = \"\\n\".join(lineas[i+1:])\n            salida_json = salida_json.split(\"```\")[0]\n            break\n    return salida_json\n\n# Instalar fuente Noto para mostrar caracteres japoneses\n!apt-get install fonts-noto-cjk -y\n\ncolores_adicionales = [nombre for (nombre, _) in ImageColor.colormap.items()]\n\ndef dibujar_bounding_boxes(imagen, bounding_boxes):\n    \"\"\"\n    Dibuja los bounding boxes sobre una imagen usando PIL y diferentes colores.\n    \"\"\"\n    img = imagen\n    ancho, alto = img.size\n    draw = ImageDraw.Draw(img)\n    colores = [\n        'red', 'green', 'blue', 'yellow', 'orange', 'pink', 'purple', 'brown',\n        'gray', 'beige', 'turquoise', 'cyan', 'magenta', 'lime', 'navy', 'maroon',\n        'teal', 'olive', 'coral', 'lavender', 'violet', 'gold', 'silver'\n    ] + colores_adicionales\n\n    bounding_boxes = parsear_json(bounding_boxes)\n    font = ImageFont.truetype(\"NotoSansCJK-Regular.ttc\", size=14)\n\n    for i, bbox in enumerate(json.loads(bounding_boxes)):\n        color = colores[i % len(colores)]\n        y1 = int(bbox[\"box_2d\"][0]/1000 * alto)\n        x1 = int(bbox[\"box_2d\"][1]/1000 * ancho)\n        y2 = int(bbox[\"box_2d\"][2]/1000 * alto)\n        x2 = int(bbox[\"box_2d\"][3]/1000 * ancho)\n        if x1 > x2:\n            x1, x2 = x2, x1\n        if y1 > y2:\n            y1, y2 = y2, y1\n        draw.rectangle(((x1, y1), (x2, y2)), outline=color, width=4)\n        if \"label\" in bbox:\n            draw.text((x1 + 8, y1 + 6), bbox[\"label\"], fill=color, font=font)\n    img.show()\n\n@dataclasses.dataclass(frozen=True)\nclass MascaraSegmentacion:\n    y0: int\n    x0: int\n    y1: int\n    x1: int\n    mascara: np.array\n    etiqueta: str\n\ndef parsear_segmentaciones(salida_predicha: str, img_alto: int, img_ancho: int):\n    items = json.loads(parsear_json(salida_predicha))\n    mascaras = []\n    for item in items:\n        abs_y0 = int(item[\"box_2d\"][0] / 1000 * img_alto)\n        abs_x0 = int(item[\"box_2d\"][1] / 1000 * img_ancho)\n        abs_y1 = int(item[\"box_2d\"][2] / 1000 * img_alto)\n        abs_x1 = int(item[\"box_2d\"][3] / 1000 * img_ancho)\n        if abs_y0 >= abs_y1 or abs_x0 >= abs_x1:\n            print(\"Bounding box inválido\", item[\"box_2d\"])\n            continue\n        etiqueta = item[\"label\"]\n        png_str = item[\"mask\"]\n        if not png_str.startswith(\"data:image/png;base64,\"):\n            print(\"Máscara inválida\")\n            continue\n        png_str = png_str.removeprefix(\"data:image/png;base64,\")\n        png_str = base64.b64decode(png_str)\n        mascara = Image.open(io.BytesIO(png_str))\n        alto_bbox = abs_y1 - abs_y0\n        ancho_bbox = abs_x1 - abs_x0\n        if alto_bbox < 1 or ancho_bbox < 1:\n            print(\"Bounding box inválido\")\n            continue\n        mascara = mascara.resize((ancho_bbox, alto_bbox), resample=Image.Resampling.BILINEAR)\n        np_mascara = np.zeros((img_alto, img_ancho), dtype=np.uint8)\n        np_mascara[abs_y0:abs_y1, abs_x0:abs_x1] = mascara\n        mascaras.append(MascaraSegmentacion(abs_y0, abs_x0, abs_y1, abs_x1, np_mascara, etiqueta))\n    return mascaras\n\ndef superponer_mascara(img: Image, mascara: np.ndarray, color: str, alpha: float = 0.7) -> Image.Image:\n    if not (0.0 <= alpha <= 1.0):\n        raise ValueError(\"Alpha debe estar entre 0.0 y 1.0\")\n    color_rgb = ImageColor.getrgb(color)\n    img_rgba = img.convert(\"RGBA\")\n    ancho, alto = img_rgba.size\n    alpha_int = int(alpha * 255)\n    color_rgba = color_rgb + (alpha_int,)\n    capa_mascara = np.zeros((alto, ancho, 4), dtype=np.uint8)\n    mascara_logica = mascara > 127\n    capa_mascara[mascara_logica] = color_rgba\n    capa_pil = Image.fromarray(capa_mascara, 'RGBA')\n    resultado = Image.alpha_composite(img_rgba, capa_pil)\n    return resultado\n\ndef dibujar_segmentaciones(img: Image, mascaras: list):\n    colores = [\n        'red', 'green', 'blue', 'yellow', 'orange', 'pink', 'purple', 'brown',\n        'gray', 'beige', 'turquoise', 'cyan', 'magenta', 'lime', 'navy', 'maroon',\n        'teal', 'olive', 'coral', 'lavender', 'violet', 'gold', 'silver'\n    ] + colores_adicionales\n    font = ImageFont.truetype(\"NotoSansCJK-Regular.ttc\", size=14)\n    for i, mascara in enumerate(mascaras):\n        color = colores[i % len(colores)]\n        img = superponer_mascara(img, mascara.mascara, color)\n    draw = ImageDraw.Draw(img)\n    for i, mascara in enumerate(mascaras):\n        color = colores[i % len(colores)]\n        draw.rectangle(((mascara.x0, mascara.y0), (mascara.x1, mascara.y1)), outline=color, width=4)\n    for i, mascara in enumerate(mascaras):\n        color = colores[i % len(colores)]\n        if mascara.etiqueta != \"\":\n            draw.text((mascara.x0 + 8, mascara.y0 - 20), mascara.etiqueta, fill=color, font=font)\n    img.show()","block_group":"5168806dc88f4a33a1b65c869f4df3da","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"a956b42d","cell_id":"c8dbe3ed268742408e021d7393ce0c35","deepnote_cell_type":"markdown"},"source":"## 8. Descargar imágenes de ejemplo\n\nDescargá imágenes de ejemplo desde URLs públicas para usarlas en los ejercicios del cuaderno.","block_group":"951553eb148f4e19996661f040ac0db0"},{"cell_type":"code","metadata":{"id":"27db6cb2","cell_id":"0d28ce84057849b991583fd94345640c","deepnote_cell_type":"code"},"source":"!wget https://storage.googleapis.com/generativeai-downloads/images/socks.jpg -O Socks.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/vegetables.jpg -O Vegetables.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/Japanese_Bento.png -O Japanese_bento.png -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/Cupcakes.jpg -O Cupcakes.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/origamis.jpg -O Origamis.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/fruits.jpg -O Fruits.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/cat.jpg -O Cat.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/pumpkins.jpg -O Pumpkins.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/breakfast.jpg -O Breakfast.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/bookshelf.jpg -O Bookshelf.jpg -q\n!wget https://storage.googleapis.com/generativeai-downloads/images/spill.jpg -O Spill.jpg -q","block_group":"379de5098d56475eb94561911f9817cd","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"b2d1f900","cell_id":"ca8d7baf8e884b6eabbaf78673140843","deepnote_cell_type":"markdown"},"source":"## 9. Cargar y mostrar una imagen\n\nCargá una imagen de ejemplo, redimensionala y mostrála para comenzar a trabajar sobre ella.","block_group":"e73466fc5eb44505b27a8a6271ad6c45"},{"cell_type":"code","metadata":{"id":"c55970f1","cell_id":"cf027ee068bd42f3880f527ea8ae02ed","deepnote_cell_type":"code"},"source":"imagen = \"Vegetables.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\n\nim = Image.open(imagen)\nim.thumbnail([620, 620], Image.Resampling.LANCZOS)\nim","block_group":"4d4a3b1c868a4659a93c05aad09d2d26","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"c59fba33","cell_id":"fd304f3234394adab453d7abd6761e93","deepnote_cell_type":"markdown"},"source":"## 10. Detectar objetos y dibujar bounding boxes\n\nEnviá la imagen y un prompt al modelo para detectar objetos y visualizar los bounding boxes sobre la imagen.","block_group":"1549a8256d074021a8fbb26be628e1bf"},{"cell_type":"code","metadata":{"id":"4f81050a","cell_id":"66b7ecb02f1b4da28ea98770c4ca862f","deepnote_cell_type":"code"},"source":"prompt = \"Detectá los bounding boxes 2D de las verduras (usá 'label' como descripción del topping)\"  # @param {type:\"string\"}\n\nim = Image.open(BytesIO(open(imagen, \"rb\").read()))\nim.thumbnail([1024, 1024], Image.Resampling.LANCZOS)\n\nrespuesta = cliente.models.generate_content(\n    model=nombre_modelo,\n    contents=[prompt, im],\n    config=types.GenerateContentConfig(\n        system_instruction=instrucciones_sistema_bbox,\n        temperature=0.5,\n        safety_settings=config_seguridad,\n    )\n)\n\nprint(respuesta.text)","block_group":"d5136c48ebcc46139dd4882e831cf480","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"af295f38","cell_id":"6202d881a6684cdc9d391f5621ea18c4","deepnote_cell_type":"code"},"source":"dibujar_bounding_boxes(im, respuesta.text)\nim","block_group":"5e98f76b63e94e3ba5f1c137eb0c1930","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"1c84bf38","cell_id":"1372c99ec4684d8898d251afcd3f1c56","deepnote_cell_type":"markdown"},"source":"## 11. Buscar objetos específicos en una imagen\n\nEjecutá prompts personalizados para buscar y resaltar objetos específicos dentro de una imagen.","block_group":"7efcfc9f89f048a093c503e579dcdbd1"},{"cell_type":"code","metadata":{"id":"0bd0a45e","cell_id":"ce0230161aa5439989a726b7bbe32202","deepnote_cell_type":"code"},"source":"imagen = \"Socks.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\nprompt = \"Mostrame las posiciones de las medias con carita\"  # @param [\"Detectá todas las medias arcoíris\", \"Encontrá todas las medias y etiquetalas con emojis\", \"Mostrame las posiciones de las medias con carita\", \"Encontrá la media que hace juego con la de arriba\"] {\"allow-input\":true}\n\nim = Image.open(imagen)\nim.thumbnail([640, 640], Image.Resampling.LANCZOS)\n\nrespuesta = cliente.models.generate_content(\n    model=nombre_modelo,\n    contents=[prompt, im],\n    config=types.GenerateContentConfig(\n        system_instruction=instrucciones_sistema_bbox,\n        temperature=0.5,\n        safety_settings=config_seguridad,\n    )\n)\n\nprint(respuesta.text)\ndibujar_bounding_boxes(im, respuesta.text)\nim","block_group":"440588120c1e423cbca5a10ec7926449","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"0eb13d27","cell_id":"c912f363672842bdbcd1e60a7fa18161","deepnote_cell_type":"markdown"},"source":"## 12. Ejemplo de razonamiento multilingüe\n\nPedile al modelo que etiquete objetos en la imagen usando japonés y traducción al inglés, demostrando capacidades multilingües.","block_group":"08cc70c760fd4cceab869dd28f6e067c"},{"cell_type":"code","metadata":{"id":"80e42789","cell_id":"da4da4efcb624249b4130463c26d1a77","deepnote_cell_type":"code"},"source":"imagen = \"Japanese_bento.png\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\nprompt = \"Detectá la comida y etiquetala con caracteres japoneses y traducción al inglés.\"  # @param [\"Detectá la comida y etiquetala con caracteres japoneses y traducción al inglés.\", \"Mostrame los platos veganos\", \"Explicá qué son esos platos en 5 palabras\", \"Encontrá los platos con alérgenos y etiquetalos\"] {\"allow-input\":true}\n\nim = Image.open(imagen)\nim.thumbnail([640, 640], Image.Resampling.LANCZOS)\n\nrespuesta = cliente.models.generate_content(\n    model=nombre_modelo,\n    contents=[prompt, im],\n    config=types.GenerateContentConfig(\n        system_instruction=instrucciones_sistema_bbox,\n        temperature=0.5,\n        safety_settings=config_seguridad,\n    )\n)\n\ndibujar_bounding_boxes(im, respuesta.text)\nim","block_group":"e1bccb78798d438b840795e418a4cfd2","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"7fba7325","cell_id":"99e1b8fd2a2f4e14b1c25225c0d10c68","deepnote_cell_type":"markdown"},"source":"## 13. Ejemplo de razonamiento espacial avanzado\n\nUsá prompts que requieran razonamiento espacial, como encontrar sombras o dar consejos basados en la imagen.","block_group":"30ad50a3ad004421b1825118b451511a"},{"cell_type":"code","metadata":{"id":"542e7ddf","cell_id":"3c48483d883347ad9d3f2e13105daf58","deepnote_cell_type":"code"},"source":"imagen = \"Origamis.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\nprompt = \"Dibujá un cuadrado alrededor de la sombra del zorro\"  # @param [\"Encontrá los dos animales de origami.\", \"¿Dónde están las sombras de los origamis?\", \"Dibujá un cuadrado alrededor de la sombra del zorro\"] {\"allow-input\":true}\n\nim = Image.open(imagen)\nim.thumbnail([640, 640], Image.Resampling.LANCZOS)\n\nrespuesta = cliente.models.generate_content(\n    model=nombre_modelo,\n    contents=[prompt, im],\n    config=types.GenerateContentConfig(\n        system_instruction=instrucciones_sistema_bbox,\n        temperature=0.5,\n        safety_settings=config_seguridad,\n    )\n)\n\ndibujar_bounding_boxes(im, respuesta.text)\nim","block_group":"5a6cb48e312945448ff522c4fcd0449d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"3d9a779e","cell_id":"c7186bd0c2124bfc904eae318245ea89","deepnote_cell_type":"code"},"source":"imagen = \"Spill.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\nprompt = \"Decime cómo limpiar mi mesa con una explicación como etiqueta. No solo etiquetes los objetos.\"  # @param [\"Mostrame dónde se derramó mi café.\", \"Decime cómo limpiar mi mesa con una explicación como etiqueta. No solo etiquetes los objetos.\", \"Dibujá un cuadrado alrededor de la sombra del zorro\"] {\"allow-input\":true}\n\nim = Image.open(imagen)\nim.thumbnail([640, 640], Image.Resampling.LANCZOS)\n\nrespuesta = cliente.models.generate_content(\n    model=nombre_modelo,\n    contents=[prompt, im],\n    config=types.GenerateContentConfig(\n        system_instruction=instrucciones_sistema_bbox,\n        temperature=0.5,\n        safety_settings=config_seguridad,\n    )\n)\n\ndibujar_bounding_boxes(im, respuesta.text)\nim","block_group":"1b99dceb23d6422aaed23508a883b3ef","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"9512fc04","cell_id":"c3f619c6e7ab41118f2c96447a8ea47d","deepnote_cell_type":"markdown"},"source":"## 14. Segmentación de imágenes y visualización de máscaras\n\nPedile al modelo máscaras de segmentación, decodificalas y superponelas sobre la imagen para una visualización avanzada.","block_group":"40454e28c88048e7ade82e80a474931a"},{"cell_type":"code","metadata":{"id":"1d9ca6b9","cell_id":"61e0673d6ac54c54a0cec312335e29d1","deepnote_cell_type":"code"},"source":"imagen = \"Cupcakes.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\nprompt = \"Dame las máscaras de segmentación para los objetos pequeños de metal, madera y vidrio (ignorá la mesa). Devolvé una lista JSON donde cada entrada tenga el bounding box en 'box_2d', la máscara en 'mask' y la etiqueta en 'label'. Usá etiquetas descriptivas.\"  # @param {type:\"string\"}\n\nim = Image.open(BytesIO(open(imagen, \"rb\").read()))\nim.thumbnail([1024, 1024], Image.Resampling.LANCZOS)\n\nrespuesta = cliente.models.generate_content(\n    model=nombre_modelo,\n    contents=[prompt, im],\n    config=types.GenerateContentConfig(\n        temperature=0.5,\n        safety_settings=config_seguridad,\n    )\n)\n\nprint(respuesta.text)\nmascaras = parsear_segmentaciones(respuesta.text, img_alto=im.size[1], img_ancho=im.size[0])\ndibujar_segmentaciones(im, mascaras)","block_group":"9df6297a960a4a4abeed3332113f4991","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"6e801533","cell_id":"57ac0c3c66b74101b14e1b8bbaae2112","deepnote_cell_type":"markdown"},"source":"## 15. Capacidades preliminares: punteo y cajas 3D\n\nLas capacidades de punteo (pointing) y cajas 3D son experimentales en los modelos Gemini. Si te interesa explorar estas funciones avanzadas, podés consultar el siguiente cuaderno de ejemplo:\n\n[Ejemplo de comprensión espacial 3D](../examples/Spatial_understanding_3d.ipynb)\n\n<a href=\"../examples/Spatial_understanding_3d.ipynb\"><img src=\"https://storage.googleapis.com/generativeai-downloads/images/box_3d.png\" height=\"400\"/></a>\n","block_group":"7e9522aa32f549f3b34b098bc44452bc"},{"cell_type":"markdown","metadata":{"id":"b9350701","cell_id":"cf405b647f0b4eecb67924edfbebc02e","deepnote_cell_type":"markdown"},"source":"## 16. ¿Qué sigue?\n\nPara ver un ejemplo más completo y de punta a punta, podés revisar el código del [ejemplo de AI Studio](https://aistudio.google.com/starter-apps/spatial) disponible en [Github](https://github.com/google-gemini/starter-applets/tree/main/spatial).\n\nTambién vas a encontrar muchos otros ejemplos de las capacidades de Gemini 2.0 en el [cookbook oficial](https://github.com/google-gemini/cookbook/tree/main/gemini-2/), incluyendo:\n\n- [API en vivo](./Get_started_LiveAPI.ipynb)\n- [Comprensión de video](./Video_understanding.ipynb)\n- [Ejemplo de marketing de mochila a propulsión](../examples/Market_a_Jet_Backpack.ipynb)\n- [Adiviná la forma](../examples/Guess_the_shape.ipynb)\n\nY, por supuesto, el ejemplo de [punteo y cajas 3D](../examples/Spatial_understanding_3d.ipynb) mencionado antes.","block_group":"f185be4652fb4d518662e142f32a892e"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9be9d3e5-4f25-48e6-912d-b59b8644d952' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"9b4adcb03da34d269ace97936600748e"}}