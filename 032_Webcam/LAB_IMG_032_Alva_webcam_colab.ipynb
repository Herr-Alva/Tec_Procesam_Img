{"cells":[{"cell_type":"markdown","metadata":{"id":"0zyILPr5KNQT","cell_id":"a659aaf99af1414b96a4192c0b4c4930","deepnote_cell_type":"markdown"},"source":"#Captura y Procesamiento de Video en Tiempo Real con Webcam\n\nEste cuaderno está diseñado para ser utilizado en un entorno educativo, explicando paso a paso cómo capturar video desde una webcam en Google Colab y cómo aplicar operaciones básicas de visión por computadora usando OpenCV en tiempo real.\n\n**Objetivos:**\n\n* Entender la interacción entre Python y JavaScript en Google Colab para acceso a hardware (webcam).\n* Implementar captura de video en tiempo real.\n* Aplicar un ejemplo de procesamiento de imágenes (detección de rostros) con OpenCV.\n* Comprender la estructura de un bucle de procesamiento de video.","block_group":"17955ef2637844cb95e9482ee4b8948a"},{"cell_type":"markdown","metadata":{"id":"84cb2e02","cell_id":"eebf6d8fc3514f2e85d1ad81ad70ca24","deepnote_cell_type":"markdown"},"source":"1. **Importar Librerías Necesarias**\n\n*   **cv2**: La biblioteca principal de OpenCV para procesamiento de imágenes y visión por computadora.\n*   **IPython.display**: Utilizado para mostrar elementos HTML y JavaScript directamente en la salida de Colab. En particular, `display` y `Javascript` para ejecutar código en el navegador, y `Image` para mostrar los fotogramas de video.\n*   **google.colab.output.eval_js**: Una función crucial de Colab que permite ejecutar una cadena de JavaScript y obtener su resultado de vuelta en Python.\n*   **base64**: Para codificar y decodificar datos binarios (como imágenes) a/desde cadenas de texto.\n*   **PIL (Pillow)** e **io**: Utilizados para manipular bytes de imagen y convertirlos entre diferentes formatos.\n*   **time**: Para introducir pausas y medir el rendimiento (FPS).\n*   **numpy**: Fundamental para el manejo de imágenes, ya que OpenCV representa las imágenes como arrays NumPy.","block_group":"3dd8fac4ca524cfd89cbc0617af408c1"},{"cell_type":"code","metadata":{"id":"q1snQaQILDkr","cell_id":"15a8bd39f1e3490c96919f860b37ba19","deepnote_cell_type":"code"},"source":"import cv2\nfrom IPython.display import display, Javascript, Image\nfrom google.colab.output import eval_js\nfrom base64 import b64decode, b64encode\nimport PIL\nimport io\nimport time\nimport numpy as np","block_group":"df8153f5c98b4c8d934db797c40690e1","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"d53ae0aa","cell_id":"a0b84fad0e6f4805aace4437556632ec","deepnote_cell_type":"markdown"},"source":"2. **Funciones JavaScript para la Interacción con la Webcam**\n\nGoogle Colab se ejecuta en servidores de Google, no directamente en tu máquina. Para acceder a tu webcam, necesitamos ejecutar código JavaScript en tu navegador. Esta celda define las funciones JavaScript necesarias para iniciar, detener y capturar fotogramas del stream de la cámara.\n\n**Explicación de las funciones JavaScript:**\n\n*   **`startStream()`**: Solicita permiso al navegador para acceder a la webcam (`navigator.mediaDevices.getUserMedia`). Si se concede, crea un elemento `<video>` en el DOM del navegador y comienza a reproducir el stream de la webcam en él. Es `async` porque `getUserMedia` es una operación asíncrona.\n*   **`stopStream()`**: Detiene todas las pistas del stream de la webcam, pausa el video y elimina los elementos de video y canvas del DOM, liberando así la cámara.\n*   **`captureFrame()`**: Toma una \"instantánea\" del fotograma actual del elemento `<video>`, lo dibuja en un `<canvas>` oculto y luego lo convierte a una cadena de datos Base64 (formato JPEG) para ser enviado a Python.\n*   **`isStreamActive()`**: Una función auxiliar para verificar el estado del stream de video en el lado del navegador.","block_group":"6c6c432e644941739737386dd35e7d33"},{"cell_type":"code","metadata":{"id":"L2SAmUdlIL2D","cell_id":"674de639765a4076bf916c434e9826ac","deepnote_cell_type":"code"},"source":"def video_stream():\n  \"\"\"\n  Define e inyecta el código JavaScript para manejar la transmisión de video\n  desde la webcam del usuario.\n  \"\"\"\n  js = Javascript('''\n    var video;\n    var stream;\n    var captureCanvas; // Canvas para capturar frames\n    var captureContext; // Contexto 2D del canvas\n\n    // Función para iniciar la transmisión de video\n    async function startStream() {\n      try {\n        stream = await navigator.mediaDevices.getUserMedia({video: true, audio: false});\n        video = document.createElement('video');\n        video.srcObject = stream;\n        // Opcional: para ver el video directamente en el DOM, descomentar\n        // video.style.maxWidth = '100%';\n        // video.style.display = 'block';\n        // document.body.appendChild(video);\n        video.play();\n        console.log(\"Stream de webcam iniciado en JS.\");\n      } catch (error) {\n        console.log(\"Error al acceder a la webcam: \", error);\n        alert(\"Por favor, permite el acceso a la cámara para usar esta función.\");\n      }\n    }\n\n    // Función para detener la transmisión de video\n    function stopStream() {\n      if (stream) {\n        stream.getTracks().forEach(track => track.stop()); // Detiene todas las pistas\n      }\n      if (video) {\n        video.pause();\n        video.srcObject = null;\n        video.remove(); // Elimina el elemento de video del DOM\n      }\n      if (captureCanvas) {\n        captureCanvas.remove(); // Elimina el canvas\n      }\n      console.log(\"Webcam detenida en JS.\");\n    }\n\n    // Función para capturar un único fotograma del video\n    function captureFrame() {\n      if (!video || !stream || !stream.active) {\n        // Asegúrate de que el video esté reproduciéndose y el stream esté activo\n        console.log(\"No hay stream de video activo para capturar.\");\n        return null;\n      }\n      if (!captureCanvas) {\n        captureCanvas = document.createElement('canvas');\n        // No lo adjuntamos al body, solo lo usamos internamente para la captura\n      }\n      // Ajustar el tamaño del canvas al tamaño actual del video\n      captureCanvas.width = video.videoWidth;\n      captureCanvas.height = video.videoHeight;\n      captureContext = captureCanvas.getContext('2d');\n      captureContext.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);\n      // Retorna el fotograma como Base64 JPEG con una calidad del 80%\n      return captureCanvas.toDataURL('image/jpeg', 0.8);\n    }\n\n    // Función para verificar si el stream de video está activo\n    function isStreamActive() {\n        return (stream && stream.active && video && !video.paused);\n    }\n\n    // Llama a startStream() inmediatamente al ejecutar esta celda para iniciar el stream\n    startStream();\n  ''')\n  display(js) # Ejecuta el JavaScript en el navegador\n\ndef video_frame():\n  \"\"\"\n  Función Python que llama a la función JavaScript 'captureFrame()'\n  para obtener un fotograma y lo devuelve como una cadena base64.\n  \"\"\"\n  data = eval_js('captureFrame()')\n  return data\n\ndef check_stream_active():\n  \"\"\"\n  Función Python que verifica el estado del stream de JavaScript\n  llamando a la función JavaScript 'isStreamActive()'.\n  \"\"\"\n  return eval_js('isStreamActive()')","block_group":"205492beb59a49138c45a42e2afc0ff3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"0788737d","cell_id":"0b4c3b361a4a4e95a0d512d3284ada6c","deepnote_cell_type":"markdown"},"source":"3. **Funciones Auxiliares de Python para Procesamiento de Imágenes**\n\nEstas funciones actúan como \"puentes\" entre el formato de datos de JavaScript (Base64) y el formato que OpenCV (NumPy arrays) entiende, y viceversa. También incluyen la lógica para cargar el clasificador de rostros de OpenCV.\n\n*   **`js_to_image(js_reply)`**: Toma la cadena Base64 que viene del navegador, la decodifica y la convierte en un array NumPy de OpenCV (BGR).\n*   **`bbox_to_bytes(bbox_array)`**: Toma un array NumPy de OpenCV (BGR o RGB, se convierte a RGB para PIL) y lo convierte en un formato de bytes JPEG que `IPython.display.Image` puede mostrar.\n*   **Carga del clasificador Haar Cascade**: El clasificador de rostros se carga una sola vez al principio. Esto es eficiente, ya que no se carga en cada fotograma.","block_group":"b1cc00d03a2945c78afd849baacc85db"},{"cell_type":"code","metadata":{"id":"cEHI-wurLhpB","cell_id":"534f494e1dcb40a29019229a014cd1c0","deepnote_cell_type":"code"},"source":"# --- Funciones Auxiliares de Python para Conversión de Imágenes ---\n\ndef js_to_image(js_reply):\n  \"\"\"\n  Decodifica la cadena de datos base64 de una imagen recibida de JavaScript\n  y la convierte a un formato de imagen OpenCV (numpy array BGR).\n  \"\"\"\n  if js_reply is None:\n    return None\n\n  # El prefijo 'data:image/jpeg;base64,' debe ser removido\n  image_bytes = b64decode(js_reply.split(',')[1])\n  # Convertir bytes a una imagen PIL (Pillow)\n  pil_img = PIL.Image.open(io.BytesIO(image_bytes))\n  # Convertir la imagen PIL a un formato de OpenCV (NumPy array BGR)\n  img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n  return img\n\ndef bbox_to_bytes(bbox_array):\n  \"\"\"\n  Convierte una imagen NumPy array (OpenCV format) a bytes JPEG\n  para que pueda ser mostrada por IPython.display.Image en Colab.\n  \"\"\"\n  # Aseguramos que la imagen esté en formato RGB para PIL antes de guardar como JPEG\n  pil_img = PIL.Image.fromarray(bbox_array, 'RGB')\n  img_byte_arr = io.BytesIO()\n  pil_img.save(img_byte_arr, format='JPEG')\n  # Obtenemos los bytes del buffer\n  bbox_bytes = img_byte_arr.getvalue()\n  return bbox_bytes\n\n# --- Carga del Clasificador de Rostros (se ejecuta una vez) ---\n# Intentamos cargar el clasificador de Haar Cascades para detección de rostros.\n# Esto se hace fuera del bucle principal para mayor eficiencia.\ntry:\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n    if face_cascade.empty():\n        # Si el archivo no se carga, lanzamos un error\n        raise IOError('No se pudo cargar el archivo XML de Haar Cascade para rostros.')\n    print(\"Clasificador de rostros cargado exitosamente.\")\nexcept Exception as e:\n    print(f\"Error al cargar el clasificador de rostros: {e}\")\n    face_cascade = None # Si la carga falla, la variable será None, y la detección se omitirá","block_group":"45bebe0aaa41493eb00ea8f261ea3e6a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"6bcdfa4b","cell_id":"295eb3378bbc4ac1952f0d955d876001","deepnote_cell_type":"markdown"},"source":"4. **Lógica de Visión por Computadora (Función `process_frame`)**\n\nAquí es donde agregaremos y probaremos diferentes algoritmos de procesamiento de imágenes de OpenCV. La función `process_frame` toma un fotograma de la cámara y aplica las operaciones deseadas antes de devolver el resultado.\n\n**Ejemplos incluidos:**\n\n*   **Detección de Rostros**: Utiliza el clasificador de Haar Cascades cargado previamente para identificar rostros y dibujar rectángulos azules alrededor de ellos.\n*   **Filtro de Escala de Grises y Canny**: (Comentado) Puedes descomentar estas líneas para ver cómo se aplican filtros de transformación de color y detección de bordes.\n*   **Dibujar Texto**: Agrega el número de fotograma actual en la esquina superior izquierda de la imagen.","block_group":"724924183d4240dc9c3ad15acadfab3c"},{"cell_type":"code","metadata":{"id":"lagPV7D_LsVg","cell_id":"539d36e0bcb2401f988d9f742bd02c83","deepnote_cell_type":"code"},"source":"# --- Lógica de Visión por Computadora (Función de Procesamiento de Fotogramas) ---\n\ndef process_frame(frame, frame_number=0):\n  \"\"\"\n  Aplica diferentes efectos de visión por computadora al fotograma de entrada.\n  Puedes activar/desactivar efectos comentando/descomentando las líneas correspondientes.\n\n  Args:\n    frame (numpy.ndarray): El fotograma de imagen en formato OpenCV (BGR).\n    frame_number (int): El número del fotograma actual.\n\n  Returns:\n    numpy.ndarray: El fotograma procesado.\n  \"\"\"\n  processed_frame = frame.copy() # Siempre trabajamos en una copia para no modificar el original\n\n  # --- Ejemplo 1: Detección de Rostros ---\n  # Solo se ejecuta si el clasificador de rostros se cargó correctamente\n  if face_cascade is not None:\n    # Convertir el fotograma a escala de grises para la detección de rostros\n    gray_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2GRAY)\n    # Detectar rostros en la imagen en escala de grises\n    # scaleFactor: Parámetro que especifica cuánto se reduce la imagen en cada escala.\n    # minNeighbors: Parámetro que especifica cuántos vecinos debe tener cada rectángulo candidato para retenerlo.\n    # minSize: Tamaño mínimo posible del objeto. Objetos más pequeños se ignoran.\n    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))\n\n    # Dibujar rectángulos alrededor de los rostros detectados\n    for (x, y, w, h) in faces:\n      cv2.rectangle(processed_frame, (x, y), (x+w, y+h), (255, 0, 0), 2) # Color azul (BGR), grosor 2\n\n  # --- Ejemplo 2: Aplicar un filtro (Escala de Grises + Detección de Bordes Canny) ---\n  # Descomenta las siguientes líneas para activar este efecto.\n  # Nota: Si activas esto, el stream se verá en blanco y negro con los bordes.\n  # gray_processed = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2GRAY)\n  # edges = cv2.Canny(gray_processed, 100, 200) # Detecta bordes\n  # processed_frame = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR) # Convierte de nuevo a BGR para visualización\n\n  # --- Ejemplo 3: Dibujar texto en el fotograma ---\n  text_to_display = f\"Fotograma: {frame_number}\"\n  # Poner texto en la imagen: (imagen, texto, origen, fuente, escala, color, grosor, tipo de línea)\n  cv2.putText(processed_frame, text_to_display, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n\n  # --- Ejemplo 4: Dibujar una forma ---\n  # Descomenta esta línea para dibujar un círculo rojo en la esquina superior derecha\n  # cv2.circle(processed_frame, (processed_frame.shape[1] - 50, 50), 30, (0, 0, 255), -1) # Círculo rojo relleno\n\n  return processed_frame","block_group":"a70e9d6998724c708b106e9050290f92","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"68c093a1","cell_id":"fcf51afa87de46e58b763c38f46220a9","deepnote_cell_type":"markdown"},"source":"5. **Bucle Principal de Captura y Visualización**\n\nEsta es la celda central que orquesta todo. Llama a las funciones JavaScript para iniciar la cámara, luego entra en un bucle infinito donde captura fotogramas, los procesa con la lógica de visión por computadora y los muestra en la salida de Colab. Incluye mecanismos de seguridad para manejar interrupciones y asegurar que la cámara se apague correctamente.\n\n**Flujo de ejecución:**\n\n1.  **Inicio de la transmisión**: Llama a `video_stream()` para activar la webcam en el navegador.\n2.  **Espera de activación**: Un bucle de espera verifica periódicamente (usando `check_stream_active()`) si la cámara está realmente activa antes de intentar capturar fotogramas. Esto previene el error \"No se recibieron datos del fotograma\".\n3.  **Bucle de captura**:\n    *   `js_reply = video_frame()`: Solicita el fotograma actual del navegador.\n    *   `img = js_to_image(js_reply)`: Convierte el fotograma Base64 a un array NumPy de OpenCV.\n    *   `processed_img = process_frame(img, frame_number=frame_count)`: Pasa el fotograma a nuestra función de procesamiento de visión por computadora.\n    *   `jpeg_bytes = bbox_to_bytes(processed_img_rgb)`: Convierte el fotograma procesado de nuevo a bytes para mostrarlo.\n    *   `display_handle.update(Image(data=jpeg_bytes))`: Actualiza la imagen mostrada en la salida de Colab.\n    *   **Cálculo de FPS**: Opcionalmente, se muestra la tasa de fotogramas por segundo para monitorear el rendimiento.\n    *   `time.sleep(0.01)`: Una pequeña pausa para evitar saturar la CPU y permitir que la interfaz de Colab se actualice fluidamente.\n4.  **Manejo de errores y finalización (try...except...finally)**:\n    *   El bucle puede ser detenido por `KeyboardInterrupt` (cuando el usuario presiona el botón de \"stop\" en Colab).\n    *   El bloque `finally` asegura que la función `stopStream()` de JavaScript sea llamada para apagar la webcam, independientemente de cómo termine el bucle.","block_group":"3713a8fe2a104fd7850d508ecf829ba8"},{"cell_type":"code","metadata":{"id":"PCE8qR6KL4wY","cell_id":"e226fa969f04496baf965b691f743fd8","deepnote_cell_type":"code"},"source":"# --- Bucle Principal de Captura y Visualización ---\n\ndef start_webcam_capture():\n  \"\"\"\n  Inicia la captura de video en tiempo real desde la webcam,\n  procesa cada fotograma y lo muestra en Colab.\n  \"\"\"\n  print(\"Iniciando transmisión de webcam... Por favor, permite el acceso a la cámara.\")\n  video_stream() # Ejecuta el JavaScript para iniciar la cámara en el navegador\n\n  # Esperar a que el stream de la cámara esté activo en el navegador\n  print(\"Esperando que el stream de la cámara esté activo\", end=\"\")\n  max_wait_time = 15 # Tiempo máximo de espera en segundos\n  wait_interval = 0.5 # Intervalo de verificación en segundos\n  start_wait = time.time()\n\n  # Bucle para verificar si el stream de la cámara está activo\n  while not check_stream_active() and (time.time() - start_wait) < max_wait_time:\n      print(\".\", end=\"\") # Muestra puntos para indicar que está esperando\n      time.sleep(wait_interval)\n  print(\"\\n\") # Salto de línea después de los puntos de espera\n\n  # Si la cámara no se activó a tiempo, informamos y salimos\n  if not check_stream_active():\n      print(\"Error: El stream de la cámara no se activó a tiempo.\")\n      print(\"Asegúrate de haber dado los permisos necesarios y de que la cámara no esté siendo usada por otra aplicación.\")\n      eval_js('stopStream();') # Intentamos apagar la cámara por si acaso\n      return # Salir de la función si la cámara no está lista\n\n  # display_handle es el objeto que se actualizará con cada nuevo fotograma en Colab\n  display_handle = display(None, display_id=True)\n  frame_count = 0\n  start_time = time.time()\n\n  try:\n    while True: # Bucle infinito para capturar y procesar fotogramas continuamente\n      # Captura un fotograma de la webcam a través de JavaScript\n      js_reply = video_frame()\n\n      # Si no se reciben datos, el stream se ha detenido o ha habido un problema\n      if js_reply is None:\n        print(\"No se recibieron datos del fotograma. La transmisión puede haberse detenido o fallado.\")\n        break # Salir del bucle principal\n\n      # Convierte el fotograma de JavaScript (cadena base64) a una imagen OpenCV (NumPy array)\n      img = js_to_image(js_reply)\n\n      # --- LLAMADA A LA LÓGICA DE VISIÓN POR COMPUTADURA ---\n      # Aquí es donde aplicamos nuestros algoritmos de procesamiento al fotograma\n      processed_img = process_frame(img, frame_number=frame_count)\n\n      # Convierte la imagen procesada (NumPy array) a bytes JPEG para la visualización en Colab\n      # Es importante convertir a RGB antes de la conversión a bytes si OpenCV está en BGR\n      processed_img_rgb = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)\n      jpeg_bytes = bbox_to_bytes(processed_img_rgb)\n\n      # Actualiza la visualización del fotograma en la salida de Colab\n      display_handle.update(Image(data=jpeg_bytes))\n\n      frame_count += 1\n      # Opcional: Calcula y muestra los FPS (Fotogramas Por Segundo) cada 30 fotogramas\n      if frame_count % 30 == 0:\n          end_time = time.time()\n          fps = frame_count / (end_time - start_time)\n          print(f\"FPS: {fps:.2f}\")\n          frame_count = 0 # Resetea el contador para el próximo cálculo de FPS\n          start_time = time.time() # Resetea el tiempo de inicio\n\n      # Pequeña pausa para evitar sobrecargar la CPU y permitir la actualización de la interfaz\n      time.sleep(0.01)\n\n  except KeyboardInterrupt:\n    # Se captura cuando el usuario presiona el botón de \"Stop\" en Colab\n    print(\"\\nCaptura de video detenida por interrupción del usuario.\")\n  except Exception as e:\n    # Captura cualquier otro error inesperado\n    print(f\"\\nOcurrió un error inesperado durante la captura: {e}\")\n  finally:\n    # Este bloque se ejecuta siempre al salir del bucle (sea por break, KeyboardInterrupt o error)\n    print(\"Limpiando y deteniendo la webcam...\")\n    eval_js('stopStream();') # Llama al JavaScript para detener la transmisión de la webcam\n    # Limpia la salida visible en Colab para eliminar el video\n    display_handle.update(Javascript('google.colab.output.clear()'))\n    print(\"Proceso de captura finalizado.\")","block_group":"87d0bda56cf142bfb4b9f41aadb31c4c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"cfa3b8bf","cell_id":"cc8381591d324e12a10bb83310b17615","deepnote_cell_type":"markdown"},"source":"6. **Ejecutar el Cuaderno**\n\nFinalmente, esta es la celda que llamarás para iniciar todo el proceso.","block_group":"926137e5c49647ca838ee157e99ad36e"},{"cell_type":"code","metadata":{"id":"krls4hMnL_h_","cell_id":"67b36cc87c5f4cc8a1ad18cb4941ca6b","deepnote_cell_type":"code"},"source":"# --- Ejecutar el Cuaderno ---\nif __name__ == '__main__':\n  start_webcam_capture()\n  print(\"\\n--- Proceso Completado ---\")\n  print(\"Para iniciar una nueva captura, simplemente ejecuta la celda anterior (Bucle Principal) nuevamente.\")\n  print(\"Si la cámara no se apaga completamente (raro, pero posible), puedes ejecutar la siguiente celda individualmente:\")\n  print(\"eval_js('stopStream();')\")","block_group":"a640c38c50c94fd09578acd795191843","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"f7decc98","cell_id":"8ca67a8262784bb3b0d20fa7e3c25ae3","deepnote_cell_type":"markdown"},"source":"7. **Detener la Transmisión de la Webcam (Manual - Opcional)**\n\nEn muy raras ocasiones, si la ejecución del bucle principal se detuvo de forma abrupta y la cámara no se apagó, puedes ejecutar esta celda para forzar el cierre del stream de la webcam.","block_group":"cdcb644b1f2149d99cdd68382745841c"},{"cell_type":"code","metadata":{"id":"hkneTcwMMYHd","cell_id":"427e8a9eadc44a5282d9f2b404b2b86d","deepnote_cell_type":"code"},"source":"# --- Detener la Transmisión de la Webcam (Manual - Opcional) ---\nfrom google.colab.output import eval_js\n\nprint(\"Intentando detener la webcam manualmente...\")\neval_js('stopStream();')\nprint(\"Webcam detenida manualmente.\")","block_group":"67a68b8252da4b42b02f7a92e344883f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"76cd86ba","cell_id":"e6fcbea7b5644048b886d06869032a52","deepnote_cell_type":"markdown"},"source":"8. **Prueba de Acceso Directo a la Webcam (JavaScript)**\n\nEste código es una prueba simple para verificar si se puede acceder a la webcam directamente utilizando JavaScript en el navegador. Intenta obtener el stream de video, crear un elemento de video y reproducirlo en la salida de Colab. También incluye un manejo básico de errores si el acceso a la cámara falla.","block_group":"c1c3a6dccd9a471cb32f9108c3ca61e8"},{"cell_type":"code","metadata":{"id":"o1etIkW1InVS","colab":{"height":497,"base_uri":"https://localhost:8080/"},"outputId":"8206ba61-0438-4304-975c-c0e0440660fe","cell_id":"308c37395c05405984e891af911190bc","deepnote_cell_type":"code"},"source":"from IPython.display import display, Javascript\n\njs_test = Javascript('''\n  navigator.mediaDevices.getUserMedia({video: true, audio: false})\n    .then(function(stream) {\n      var video = document.createElement('video');\n      video.srcObject = stream;\n      video.style.maxWidth = '100%'; // Para que el video se ajuste\n      video.style.display = 'block'; // Asegura que se muestre\n      document.body.appendChild(video);\n      video.play();\n      console.log('Cámara activada en JavaScript. Buscando video...');\n    })\n    .catch(function(error) {\n      console.log('Error al acceder a la cámara:', error);\n      alert('Error al acceder a la cámara. Revisa los permisos: ' + error.name);\n    });\n''')\ndisplay(js_test)","block_group":"5702662e1cd44e4ca8bc693833476607","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n  navigator.mediaDevices.getUserMedia({video: true, audio: false})\n    .then(function(stream) {\n      var video = document.createElement('video');\n      video.srcObject = stream;\n      video.style.maxWidth = '100%'; // Para que el video se ajuste\n      video.style.display = 'block'; // Asegura que se muestre\n      document.body.appendChild(video);\n      video.play();\n      console.log('Cámara activada en JavaScript. Buscando video...');\n    })\n    .catch(function(error) {\n      console.log('Error al acceder a la cámara:', error);\n      alert('Error al acceder a la cámara. Revisa los permisos: ' + error.name);\n    });\n"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/a7cc131d-61f6-43d7-8fd4-9f7b1352d300","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9be9d3e5-4f25-48e6-912d-b59b8644d952' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"dbef7486e4844733800fe78fce103e87"}}